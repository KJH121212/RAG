## 📄 문서 생성 및 임베딩 전략

### 1. 문서 생성

- 원본 JSON은 서비스 정보 리스트 형태
- 각 항목(서비스 1건)을 하나의 LangChain `Document`로 변환
- 결과적으로 **서비스 개수 = 문서 개수**

---

### 2. 청크 분할 방식

청크는 LLM 임베딩을 위해 문서를 일정 단위로 나눈 것

#### 1️⃣ 문자 길이 기반 분할

- **방식**: `RecursiveCharacterTextSplitter` 등 사용  
- **예시**: `chunk_size=1000`, `chunk_overlap=100`

**장점**
- 빠르게 처리 가능
- 직관적이고 디버깅이 쉬움

**단점**
- LLM은 문자 단위가 아닌 **토큰 단위로 처리**
- 문장이 중간에 잘려 **문맥 단절** 가능성 있음

---

#### 2️⃣ 토큰 개수 기반 분할

- **방식**: `TokenTextSplitter` 사용  
- **예시**: `chunk_size=512`, `chunk_overlap=50`

**장점**
- LLM 입력 단위인 **토큰 기준**으로 분할 → **문맥 손실 최소화**
- 긴 문장을 더 정확하게 포함 가능

**단점**
- 토크나이저 로딩 및 분할 속도가 문자 기반보다 느림
- 청크 수 증가 → 임베딩 비용 증가

---

#### ✅ 분할 방식 선택 이유: 토큰 개수 기반

> LLM은 토큰 단위로 문장을 처리하고 이해하기 때문에  
> **문맥 단절을 최소화할 수 있는 토큰 기반 분할이 성능 면에서 더 적합**하다고 판단함.

- 조건, 대상, 신청방법 등이 유기적으로 연결된 문서 특성상 **문맥 보존이 중요**
- 초기 설정(`chunk_size=512`) → 약 **90,000개 청크** 발생 → 비용 과다
- `chunk_size=1000`으로 늘려 **청크 수를 약 50,000개**로 감소
- 긴 청크는 RAG 검색 품질에도 유리 → **비용 대비 효율적**

---

### 3. 임베딩 비용 문제

- **Solar API 기준**: 약 `$0.10 / 1M tokens`
- 전체 문서 임베딩 시 약 `$2.00` 발생
- **전체를 반복적으로 임베딩하는 것은 비효율적**

---

### 💡 해결 방법: 변경된 문서만 임베딩

#### ✅ 핵심 아이디어

> 기존 임베딩 결과는 재사용하고,  
> **바뀐 문서만 선별하여 다시 임베딩**한다.

---

#### 🔄 변경 문서 감지 전략 비교

| 항목             | 해시 기반 비교                            | 기존 JSON 비교                             |
|------------------|--------------------------------------------|--------------------------------------------|
| 비교 단위        | 문자열(`page_content`) 전체                | 구조화된 딕셔너리(`dict`)                  |
| 기준 키          | 문자열 전체 해시값                         | `서비스ID`                                 |
| 구현 난이도      | 간단 (해시 한 줄 생성)                    | 약간 복잡 (`dict` 비교 필요)               |
| 변경 감지 정확도 | 텍스트 일부 변경까지 감지 가능             | 필드 값 단위로 변경 감지 가능              |
| 변경 원인 파악   | 어려움 (어디가 바뀌었는지 모름)            | 용이 (어떤 필드가 바뀌었는지 명확히 알 수 있음) |
| 별도 저장 필요   | 해시 저장소 필요 (`embedding_hashes.json`) | 없음 (기존 JSON만 유지하면 됨)             |
| 디버깅 편의성    | 낮음                                       | 높음                                       |
| 활용 환경        | 문서 기반 시스템                           | 구조화된 데이터(JSON) 기반 시스템          |

---

#### ✅ 선택 전략: 기존 JSON 비교 방식

**선택 이유**
- 정부 서비스 데이터는 **구조화된 JSON 형태**로 주어짐
- 각 서비스는 고유한 `서비스ID`로 명확하게 식별됨
- 정기적으로 전체 JSON이 갱신됨
- 구조화된 데이터를 비교하면 변경된 **필드**까지 추적 가능
- 변경 감지뿐 아니라 **변경 이유 파악**도 가능

> → 따라서 **기존 JSON과 새로운 JSON을 비교하는 방식**이  
> **가장 현실적이고 효율적인 전략**

→ **EDA에서 구현 필요**, `prev.json` 백업 필수

---

### 🔄 변경 감지 및 임베딩 전략

#### ✅ 변경 유형 분류 (서비스ID 기준)

| 유형     | 조건                                                     | 처리 방식             |
|----------|----------------------------------------------------------|------------------------|
| 추가됨   | new에는 있고, prev에는 없음                              | 새로 임베딩 (`add`)   |
| 변경됨   | 두 JSON에 모두 존재하지만 내용이 다름                     | 재임베딩 (`update`)   |
| 삭제됨   | prev에는 있는데 new에는 없음                             | 벡터 DB에서 제거 (`delete`) |

---

### ⚠️ 문제: `서비스명` 중복으로 인한 데이터 손실

#### 📌 원인

- 동일한 `서비스명`을 가진 항목이 JSON 내에 여러 개 존재
- `dict`로 변환 시 `서비스명`을 키로 사용하면 **중복 항목 덮어쓰기 발생**
- → 그 결과 **전체 문서 수가 줄어드는 문제 발생**

---

#### 🔍 중복 사례 분석

> 자세한 내용은 `EDA` 폴더의 `EDA.ipynb` 참고

---

### ✅ 데이터 전처리 전략

| 구분 | 조건 | 처리 방식 | 통합 방식 상세 |
|------|------|------------|----------------|
| 1. 완전 중복 제거 | `서비스명`, `서비스ID`, 내용이 모두 동일 | 하나만 유지, 나머지 제거 | 완전히 동일한 항목 제거 |
| 2. ID/이름 같고 내용 다름 | `서비스명`, `서비스ID`는 같지만 세부 내용 다름 | 하나로 병합 | - 대표 ID 및 이름 유지<br>- `조건` 필드만 다르면 조건 병합<br>- 그 외 문자열: `||` 병합, dict: key 기준 병합 |
| 3. 이름 같고 ID 다름 | `서비스명` 동일, `서비스ID` 다름 | 하나로 병합 | - 대표 ID: 첫 항목 사용<br>- 문자열: `||` 병합<br>- 리스트: 중복 제거 후 병합<br>- dict: key 기준 병합<br>- 숫자 범위 (`대상연령` 등): min/max 병합 |

---

### 📊 전처리 결과

| 단계     | 항목 수  |
|----------|----------|
| 병합 전  | 26,573개 |
| 병합 후  | 8,850개  |