## 📄 문서 생성 및 임베딩 전략

### 1. 문서 생성

- 원본 JSON은 서비스 정보 리스트 형태
- 각 항목(서비스 1건)을 하나의 LangChain `Document`로 변환
- 결과적으로 **서비스 개수 = 문서 개수**

---

### 2. 청크 분할 방식

청크는 LLM 임베딩을 위해 문서를 일정 단위로 나눈 것

#### 1️⃣ 문자 길이 기반 분할

- 방식: `RecursiveCharacterTextSplitter` 등 사용
- 예: `chunk_size=1000`, `chunk_overlap=100`

**장점**
- 빠르게 처리 가능
- 직관적이고 디버깅이 쉬움

**단점**
- LLM은 문자 단위가 아닌 **토큰 단위로 처리**함
- 문장이 중간에 잘려 **문맥 단절** 가능성 있음

---

#### 2️⃣ 토큰 개수 기반 분할

- 방식: `TokenTextSplitter` 사용
- 예: `chunk_size=512`, `chunk_overlap=50`

**장점**
- LLM 입력 단위인 **토큰 기준**으로 분할 → **문맥 손실 최소화**
- 긴 문장을 더 정확하게 포함 가능

**단점**
- 토크나이저 로딩 및 분할 속도가 문자 기반보다 느림 (차이는 크지 않음)
- 청크 수 증가 → 임베딩 비용 증가

---

### ✅ 분할 방식 선택 이유: 토큰 개수 기반

> LLM은 토큰 단위로 문장을 처리하고 이해하기 때문에  
> **문맥 단절을 최소화할 수 있는 토큰 기반 분할이 성능 면에서 더 적합**하다고 판단함.

- 특히, 서비스별 문서는 조건, 대상, 신청방법 등이 **유기적으로 연결된 정보**로 구성됨 → 문맥 보존이 중요
- 초기 설정(`chunk_size=512`)에서는 **청크 수 약 90,000개**로 비용이 과다하게 발생함
- `chunk_size=1000`으로 늘려 **청크 수를 약 50,000개**로 줄임
- 문맥을 충분히 포함한 긴 청크는 RAG 검색 품질에도 도움이 되므로  
  **오히려 비용 대비 효율적인 선택**이라 판단

---

### 3. 임베딩 비용 문제

- Solar API 기준: 약 **$0.10 / 1M tokens**
- 현재 전체 문서 임베딩 시 약 **$2.00**의 비용 발생
- → 전체를 반복적으로 임베딩하는 것은 **비용 낭비**

---

## 💡 해결 방법: 변경된 문서만 임베딩

### ✅ 핵심 아이디어

> 기존 임베딩 결과는 재사용하고,  
> **바뀐 문서만 선별하여 다시 임베딩**한다.

---

### 🔄 변경 문서 감지 전략 비교

| 항목             | 해시 기반 비교                            | 기존 JSON 비교                             |
|------------------|--------------------------------------------|--------------------------------------------|
| 비교 단위        | 문자열(`page_content`) 전체                | 구조화된 딕셔너리(`dict`)                  |
| 기준 키          | 문자열 전체 해시값                         | `서비스ID`                                 |
| 구현 난이도      | 간단 (해시 한 줄 생성)                    | 약간 복잡 (`dict` 비교 필요)               |
| 변경 감지 정확도 | 텍스트 일부 변경까지 감지 가능             | 필드 값 단위로 변경 감지 가능              |
| 변경 원인 파악   | 어려움 (어디가 바뀌었는지 모름)            | 용이 (어떤 필드가 바뀌었는지 명확히 알 수 있음) |
| 별도 저장 필요   | 해시 저장소 필요 (`embedding_hashes.json`) | 없음 (기존 JSON만 유지하면 됨)             |
| 디버깅 편의성    | 낮음                                       | 높음                                       |
| 활용 환경        | 문서 기반 시스템                           | 구조화된 데이터(JSON) 기반 시스템          |

---

### ✅ 선택 전략: 기존 JSON 비교 방식

#### 선택 이유

- 정부 서비스 데이터는 **구조화된 JSON 형태**로 주어지며
- 각 서비스는 고유한 `서비스ID`로 명확하게 식별됨
- 데이터는 정기적으로 전체 JSON이 갱신되는 형태로 수집됨
- 구조화된 데이터를 비교하면 변경된 **필드**까지 추적 가능
- 변경 감지뿐 아니라 **변경 이유까지 파악 가능**해 유지보수에 유리함

> 따라서 이 프로젝트에서는  
> **기존 JSON과 새로운 JSON을 비교하는 방식이 가장 현실적이고 효율적인 전략**이다.
= EDA 에서 변경 해야함. prev.json으로 백업 생성

## 🔄 변경 감지 및 임베딩 전략

### ✅ 변경 유형 분류 (서비스ID 기준)

| 유형     | 조건                                                         | 처리 방식             |
|----------|--------------------------------------------------------------|------------------------|
| 추가됨   | new에는 있고, prev에는 없음                                  | 새로 임베딩 (`add`)   |
| 변경됨   | 두 JSON에 모두 존재하지만 내용(json.dumps)이 다름            | 재임베딩 (`update`)   |
| 삭제됨   | prev에는 있는데 new에는 없음                                 | 벡터 DB에서 제거 (`delete`) |

## ⚠️ 문제: `서비스명` 중복으로 인한 데이터 손실

### 📌 원인
- JSON 내에 **동일한 `서비스명`을 가진 항목이 여러 개** 존재함
- `dict`로 변환할 때 `서비스명`을 키로 사용하면 **중복 항목이 덮어써짐**
- → 그 결과 **전체 문서 수가 줄어드는 문제 발생**

